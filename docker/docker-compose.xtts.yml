version: "3.9"

services:
  xtts-teacher:
    build:
      context: ..
      dockerfile: docker/Dockerfile.xtts_teacher
    container_name: "${VOICE_ID:-voice1}_xtts_teacher"
    restart: unless-stopped

    # GPU wiring is environment-dependent; add runtime: nvidia if GPU is available
    # For now we pass device choice via env and let TTS(api) pick CPU/GPU.
    environment:
      VOICE_ID: "${VOICE_ID:-voice1}"
      XTTS_MODEL_NAME: "${XTTS_MODEL_NAME:-tts_models/multilingual/multi-dataset/xtts_v2}"
      XTTS_SPEAKER_WAVS: "${XTTS_SPEAKER_WAVS}"
      XTTS_LANGUAGE: "${XTTS_LANGUAGE:-en}"
      XTTS_DEVICE: "${XTTS_DEVICE:-cuda}"
      COQUI_TOS_AGREED: "1"  # Auto-accept Terms of Service for non-interactive use
      TTS_HOME: "/root"  # TTS will use /root/tts/ (where we mount the cache)

    volumes:
      # Host directory with speaker reference WAVs
      - "${REFERENCE_AUDIO_DIR}:/speakers:ro"
      # Host directory with XTTS model cache (to avoid re-downloading)
      # When TTS_HOME=/root, TTS creates /root/tts/ for models
      # So we mount the host's tts subdirectory to /root/tts in the container
      # Read-write needed for TOS file, but model files are read-only from host perspective
      - "${MODEL_CACHE_DIR}/tts:/root/tts:rw"

    ports:
      - "${XTTS_PORT:-9010}:9010"

