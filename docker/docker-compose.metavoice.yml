services:
  metavoice-teacher:
    build:
      context: ..
      dockerfile: docker/Dockerfile.metavoice.inference
    container_name: "${VOICE_ID:-voice1}_metavoice_teacher"
    image: metavoice-5080
    environment:
      - CUDA_VISIBLE_DEVICES=0
      # HF repo can be overridden via env file:
      - HUGGINGFACE_REPO_ID=${METAVOICE_REPO_ID:-metavoiceio/metavoice-1B-v0.1}
      # PyTorch memory optimization to reduce fragmentation and prevent CUDA OOM
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      # NVIDIA runtime environment variables for GPU access
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Ensure CUDA libraries are in library path, but prioritize PyTorch's bundled cuDNN
      # PyTorch comes with cuDNN 9.10.2 bundled, so we put it first to avoid version conflicts
      # NOTE: We exclude /usr/lib/x86_64-linux-gnu to prevent finding system cuDNN 9.8.0
      - LD_LIBRARY_PATH=/usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/cuda/lib64:/usr/local/cuda/targets/x86_64-linux/lib:${LD_LIBRARY_PATH}
      # Force PyTorch CUDA detection (may help with CDI initialization)
      - TORCH_USE_CUDA_DSA=0
    # GPU passthrough configuration using CDI (Container Device Interface)
    # Required for Blackwell GPUs - traditional nvidia driver doesn't work
    devices:
      - "nvidia.com/gpu=all"
    ports:
      - "${METAVOICE_PORT:-9010}:9010"
    volumes:
      # optional: share HF cache
      - ~/.cache/huggingface:/root/.cache/huggingface:rw
      # reference clips from host
      - "${REFERENCE_AUDIO_DIR}:/speakers:ro"
