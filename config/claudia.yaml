voice_id: claudia
language: en_GB
paths:
  raw_audio_dir: data_raw/claudia/input_audio
  normalized_dir: data_processed/claudia/normalized
  segments_dir: data_processed/claudia/segments
  asr_metadata: data_processed/claudia/asr_segments.jsonl
  real_dataset_dir: datasets/claudia/real
  synth_dataset_dir: datasets/claudia/synth
  combined_dataset_dir: datasets/claudia/combined
  tms_workspace_dir: tms_workspace
  output_models_dir: models/claudia
asr:
  model_size: medium.en
  device: cuda
  beam_size: 5
  max_segment_seconds: 15
  min_segment_seconds: 1.0
  min_confidence: 0.7
phoneme_check:
  language: en-gb
  max_phoneme_distance: 0.1
  use_tts_roundtrip: true
synthetic:
  enabled: true
  corpus_text_path: data_raw/external_corpus/corpus.txt
  max_sentences: 3020
  tts_backend: http
  tts_http:
    base_url: http://localhost:9010/tts
    voice_id: claudia_clone
  teacher:
    kind: xtts
    port: 9010
    model_name: tts_models/multilingual/multi-dataset/xtts_v2
    language: en
    device: cuda
    reference_audio_dir: datasets/claudia/real_clean/wavs
    num_reference_clips: 0
    workers: 2  # Reduced from 3 to prevent GPU OOM (2 workers = ~8GB models, leaves ~7GB for inference)
  # max_parallel_jobs is auto-calculated as workers * 2 (12 in this case)
  # You can override it by uncommenting the line below:
  # max_parallel_jobs: 12
training:
  base_checkpoint: en_GB-base-medium.ckpt
  batch_size: 32
  max_epochs: 1000
  quality: medium
  accelerator: gpu
  devices: 1
tms:
  enable_tts_dojo: true
  docker_compose_file: docker/docker-compose.training.yml
  project_name: claudia-voice
  expose_tensorboard: true
  tensorboard_port: 6006
